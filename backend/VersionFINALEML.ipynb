{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41177be7-327f-4518-896f-aed471d7f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c21a78ac-8238-4d02-826e-4944499d8a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cfa168d-4c08-493b-8059-44f32aedec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= 'C:/Users/bensa/deeplearningProjet1/IOTProjet/plant_growth_data.csv'\n",
    "data = pd.read_csv(path,  encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf0d3ace-d0f8-4dbb-a9b4-d421cfdb30c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba5123b5-f460-4761-83c0-0d50f4531e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainset, testset = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e07e9d6-b21c-4740-9ad1-20fc41747162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soil_Type\n",
      "Water_Frequency\n",
      "Fertilizer_Type\n"
     ]
    }
   ],
   "source": [
    "df['Water_Frequency'].dtype \n",
    "\n",
    "for i in list(df.columns):\n",
    "    if pd.api.types.is_object_dtype(df[i]) :\n",
    "        print(i)\n",
    "\n",
    "\n",
    "for i in list(df.columns) :\n",
    "    if pd.api.types.is_object_dtype(df[i]) :\n",
    "        df[i]=df[i].astype('category')\n",
    "        df[i]=df[i].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff4847a9-1ea0-49e0-a59c-a7d64f1b652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# effacer toute  les ligne avec des valeurs manquantes \n",
    "def imputation(df):\n",
    "    #df['is na'] = (df['Parainfluenza 3'].isna()) | (df['Leukocytes'].isna())\n",
    "    #df = df.fillna(-999)\n",
    "    df = df.dropna(axis=0)\n",
    "    return  df\n",
    "\n",
    "\n",
    "def preprocessing(df):\n",
    "    \n",
    "    for i in list(df.columns) :\n",
    "        if pd.api.types.is_object_dtype(df[i]) :\n",
    "            df[i]=df[i].astype('category')\n",
    "            df[i]=df[i].cat.codes\n",
    "\n",
    "    \n",
    "    X = df.drop('Growth_Milestone', axis=1)\n",
    "    y = df['Growth_Milestone']\n",
    "    \n",
    "    print(y.value_counts())\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fc77710-7c75-42e4-bb85-d6cb7563a975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growth_Milestone\n",
      "1    77\n",
      "0    77\n",
      "Name: count, dtype: int64\n",
      "Growth_Milestone\n",
      "0    20\n",
      "1    19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = preprocessing(trainset)\n",
    "X_test, y_test = preprocessing(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f175c1-41d1-4411-8ab1-57f679a34e92",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "733ea7d3-6307-4ee6-9951-a5fdacb81439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "clf = LogisticRegressionCV(cv=10, random_state=0,scoring='accuracy', penalty='l2').fit( X_train, y_train)\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cfd8c1c3-f517-4895-8c2f-b8092958d081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe prédite: [1]\n",
      "Probabilités: [[0.45913407 0.54086593]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bensa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegressionCV was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\bensa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegressionCV was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Prédiction et probabilités\n",
    "X = np.array([1,8,2,1,85,25]).reshape(-1, 1)\n",
    "y_pred = clf.predict(X.T)\n",
    "print(\"Classe prédite:\", y_pred)\n",
    "\n",
    "# Probabilités pour chaque classe\n",
    "probabilities = clf.predict_proba(X.T)\n",
    "print(\"Probabilités:\", probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a616c6b-b6e4-4709-bd7e-7fec57b80647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "# Création du pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "# Entraînement du pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Enregistrement des composants\n",
    "joblib.dump(pipeline.named_steps['scaler'], 'scaler.pkl')\n",
    "joblib.dump(pipeline.named_steps['clf'], 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d39ae6-07d3-4c7c-8cc0-f895e10def9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
